#!/usr/bin/env python3
"""
GPU –∏ CUDA diagnostics –¥–ª—è AI Entities training
"""

import sys

def check_gpu():
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å GPU –∏ CUDA –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å"""
    print("=" * 70)
    print("  üîç GPU & CUDA Diagnostics")
    print("=" * 70)
    
    try:
        import torch
        print(f"\n‚úì PyTorch –≤–µ—Ä—Å–∏—è: {torch.__version__}")
        
        cuda_available = torch.cuda.is_available()
        print(f"  CUDA –¥–æ—Å—Ç—É–ø–µ–Ω: {cuda_available}")
        
        if cuda_available:
            print(f"  CUDA –≤–µ—Ä—Å–∏—è: {torch.version.cuda}")
            print(f"  cuDNN –≤–µ—Ä—Å–∏—è: {torch.backends.cudnn.version()}")
            
            device_count = torch.cuda.device_count()
            print(f"\n  –ù–∞–π–¥–µ–Ω–æ GPU: {device_count}")
            
            for i in range(device_count):
                print(f"\n  ‚îî‚îÄ GPU {i}: {torch.cuda.get_device_name(i)}")
                props = torch.cuda.get_device_properties(i)
                print(f"     –í—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–∞—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å: {props.major}.{props.minor}")
                print(f"     –í—Å–µ–≥–æ –ø–∞–º—è—Ç–∏: {props.total_memory / 1e9:.2f} GB")
                print(f"     Max –ø–æ—Ç–æ–∫–æ–≤ –Ω–∞ –±–ª–æ–∫: {props.max_threads_per_block}")
                print(f"     Max –±–ª–æ–∫–æ–π —Ä–∞–∑–º–µ—Ä: {props.max_block_dim}")
            
            # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ç–µ–∫—É—â–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏
            print(f"\n  –¢–µ–∫—É—â–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ GPU 0:")
            allocated = torch.cuda.memory_allocated(0) / 1e9
            reserved = torch.cuda.memory_reserved(0) / 1e9
            print(f"     –í—ã–¥–µ–ª–µ–Ω–æ: {allocated:.2f} GB")
            print(f"     –ó–∞—Ä–µ–∑–µ—Ä–≤–∏—Ä–æ–≤–∞–Ω–æ: {reserved:.2f} GB")
            
            # –ü–æ–¥—Å–∫–∞–∑–∫–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
            print(f"\n  üìä –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è:")
            total_mem = props.total_memory / 1e9
            if total_mem >= 16:
                print(f"     ‚úì –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–∞–º—è—Ç–∏ –¥–ª—è batch_size=512+")
                print(f"     ‚úì –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: --batch-size 512 --n-steps 8192 --n-envs 16")
            elif total_mem >= 8:
                print(f"     ‚úì –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–∞–º—è—Ç–∏ –¥–ª—è batch_size=256")
                print(f"     ‚úì –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: --batch-size 256 --n-steps 4096 --n-envs 12")
            else:
                print(f"     ‚ö† –û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–∞—è –ø–∞–º—è—Ç—å")
                print(f"     ‚ö† –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: --batch-size 128 --n-steps 2048 --n-envs 8")
        else:
            print(f"\n  ‚ö† CUDA –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω - –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω CPU")
            print(f"    –î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è GPU:")
            print(f"    1. –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ GPU —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ (nvidia-smi)")
            print(f"    2. –ü–µ—Ä–µ—É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ PyTorch —Å CUDA –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π:")
            print(f"       pip install torch --index-url https://download.pytorch.org/whl/cu118")
        
        print("\n" + "=" * 70)
        print("  Training Optimization Info")
        print("=" * 70)
        
        if cuda_available:
            print("\n‚úÖ GPU –æ–±—É—á–µ–Ω–∏–µ –¥–æ—Å—Ç—É–ø–Ω–æ!")
            print("\n–î–ª—è –∑–∞–ø—É—Å–∫–∞ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ GPU –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ:")
            print("  python train.py --agent herbivore --steps 200000 --gpu")
            print("\n–û–±—â–∏–µ –∫–æ–º–∞–Ω–¥—ã:")
            print("  python train.py --agent herbivore --steps 200000 --device cuda")
            print("  python train.py --agent predator --steps 500000 --gpu")
            print("  python train.py --agent smart --steps 1000000 --gpu --curriculum-smart")
            print("\nMonirotoring –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è:")
            print("  watch -n 1 nvidia-smi  # –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å GPU")
            print("  tensorboard --logdir logs  # –°–º–æ—Ç—Ä–µ—Ç—å –º–µ—Ç—Ä–∏–∫–∏")
        else:
            print("\n‚ö†Ô∏è GPU –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ - –æ–±—É—á–µ–Ω–∏–µ –±—É–¥–µ—Ç –Ω–∞ CPU")
            print("\n–î–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–∞ CPU –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ:")
            print("  python train.py --agent herbivore --steps 200000")
        
        print("\n" + "=" * 70)
        
        return cuda_available
        
    except ImportError:
        print("‚úó PyTorch –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞!")
        print("  –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install torch")
        return False
    except Exception as e:
        print(f"‚úó –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ: {e}")
        return False


if __name__ == "__main__":
    cuda_ok = check_gpu()
    sys.exit(0 if cuda_ok else 1)
